{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "from torchvision.ops.boxes import nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                filename class                    bbox\n113    14_010_1_0037.bmp   [1]  [[125, 227, 171, 266]]\n929    14_051_8_0016.bmp   [1]   [[134, 96, 190, 115]]\n676    14_044_3_0042.bmp   [1]  [[222, 290, 238, 302]]\n344   14_021_34_0030.bmp   [1]  [[370, 152, 396, 174]]\n217    14_017_1_0033.bmp   [1]  [[206, 196, 229, 213]]\n323   14_021_32_0022.bmp   [1]  [[398, 200, 427, 230]]\n815    14_050_9_0020.bmp   [1]  [[259, 131, 272, 165]]\n1393   14_094_3_0052.bmp   [1]  [[207, 107, 233, 147]]\n1333   14_076_4_0026.bmp   [1]  [[198, 137, 261, 165]]\n604    14_040_7_0009.bmp   [1]   [[86, 208, 101, 235]]\n833    14_050_9_0040.bmp   [1]  [[244, 123, 265, 161]]\n515    14_040_1_0021.bmp   [1]  [[262, 182, 271, 198]]\n502    14_034_7_0044.bmp   [1]  [[157, 101, 189, 124]]\n261   14_021_29_0034.bmp   [1]    [[225, 74, 244, 97]]\n1181   14_070_5_0054.bmp   [1]   [[99, 164, 124, 188]]\n1338   14_094_2_0036.bmp   [1]  [[141, 128, 163, 154]]\n1157   14_070_5_0027.bmp   [1]   [[76, 174, 106, 198]]\n939    14_051_8_0027.bmp   [1]   [[155, 87, 204, 107]]\n911    14_051_5_0037.bmp   [1]  [[153, 119, 201, 139]]\n559    14_040_3_0010.bmp   [1]  [[183, 315, 203, 333]]\n360   14_021_35_0016.bmp   [1]  [[362, 101, 382, 136]]\n1023   14_067_4_0028.bmp   [1]  [[269, 224, 288, 270]]\n610    14_040_7_0015.bmp   [1]    [[43, 181, 64, 200]]\n432   14_021_38_0032.bmp   [1]  [[155, 308, 210, 334]]\n456    14_034_6_0024.bmp   [1]  [[139, 110, 161, 142]]\n139    14_010_6_0027.bmp   [1]  [[154, 224, 183, 274]]\n921    14_051_6_0029.bmp   [1]  [[265, 189, 282, 227]]\n1161   14_070_5_0031.bmp   [1]  [[111, 188, 135, 216]]\n540    14_040_2_0018.bmp   [1]  [[300, 318, 316, 345]]\n1310   14_075_8_0033.bmp   [1]   [[188, 86, 240, 118]]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>class</th>\n      <th>bbox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>113</th>\n      <td>14_010_1_0037.bmp</td>\n      <td>[1]</td>\n      <td>[[125, 227, 171, 266]]</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>14_051_8_0016.bmp</td>\n      <td>[1]</td>\n      <td>[[134, 96, 190, 115]]</td>\n    </tr>\n    <tr>\n      <th>676</th>\n      <td>14_044_3_0042.bmp</td>\n      <td>[1]</td>\n      <td>[[222, 290, 238, 302]]</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>14_021_34_0030.bmp</td>\n      <td>[1]</td>\n      <td>[[370, 152, 396, 174]]</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>14_017_1_0033.bmp</td>\n      <td>[1]</td>\n      <td>[[206, 196, 229, 213]]</td>\n    </tr>\n    <tr>\n      <th>323</th>\n      <td>14_021_32_0022.bmp</td>\n      <td>[1]</td>\n      <td>[[398, 200, 427, 230]]</td>\n    </tr>\n    <tr>\n      <th>815</th>\n      <td>14_050_9_0020.bmp</td>\n      <td>[1]</td>\n      <td>[[259, 131, 272, 165]]</td>\n    </tr>\n    <tr>\n      <th>1393</th>\n      <td>14_094_3_0052.bmp</td>\n      <td>[1]</td>\n      <td>[[207, 107, 233, 147]]</td>\n    </tr>\n    <tr>\n      <th>1333</th>\n      <td>14_076_4_0026.bmp</td>\n      <td>[1]</td>\n      <td>[[198, 137, 261, 165]]</td>\n    </tr>\n    <tr>\n      <th>604</th>\n      <td>14_040_7_0009.bmp</td>\n      <td>[1]</td>\n      <td>[[86, 208, 101, 235]]</td>\n    </tr>\n    <tr>\n      <th>833</th>\n      <td>14_050_9_0040.bmp</td>\n      <td>[1]</td>\n      <td>[[244, 123, 265, 161]]</td>\n    </tr>\n    <tr>\n      <th>515</th>\n      <td>14_040_1_0021.bmp</td>\n      <td>[1]</td>\n      <td>[[262, 182, 271, 198]]</td>\n    </tr>\n    <tr>\n      <th>502</th>\n      <td>14_034_7_0044.bmp</td>\n      <td>[1]</td>\n      <td>[[157, 101, 189, 124]]</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>14_021_29_0034.bmp</td>\n      <td>[1]</td>\n      <td>[[225, 74, 244, 97]]</td>\n    </tr>\n    <tr>\n      <th>1181</th>\n      <td>14_070_5_0054.bmp</td>\n      <td>[1]</td>\n      <td>[[99, 164, 124, 188]]</td>\n    </tr>\n    <tr>\n      <th>1338</th>\n      <td>14_094_2_0036.bmp</td>\n      <td>[1]</td>\n      <td>[[141, 128, 163, 154]]</td>\n    </tr>\n    <tr>\n      <th>1157</th>\n      <td>14_070_5_0027.bmp</td>\n      <td>[1]</td>\n      <td>[[76, 174, 106, 198]]</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>14_051_8_0027.bmp</td>\n      <td>[1]</td>\n      <td>[[155, 87, 204, 107]]</td>\n    </tr>\n    <tr>\n      <th>911</th>\n      <td>14_051_5_0037.bmp</td>\n      <td>[1]</td>\n      <td>[[153, 119, 201, 139]]</td>\n    </tr>\n    <tr>\n      <th>559</th>\n      <td>14_040_3_0010.bmp</td>\n      <td>[1]</td>\n      <td>[[183, 315, 203, 333]]</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>14_021_35_0016.bmp</td>\n      <td>[1]</td>\n      <td>[[362, 101, 382, 136]]</td>\n    </tr>\n    <tr>\n      <th>1023</th>\n      <td>14_067_4_0028.bmp</td>\n      <td>[1]</td>\n      <td>[[269, 224, 288, 270]]</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>14_040_7_0015.bmp</td>\n      <td>[1]</td>\n      <td>[[43, 181, 64, 200]]</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>14_021_38_0032.bmp</td>\n      <td>[1]</td>\n      <td>[[155, 308, 210, 334]]</td>\n    </tr>\n    <tr>\n      <th>456</th>\n      <td>14_034_6_0024.bmp</td>\n      <td>[1]</td>\n      <td>[[139, 110, 161, 142]]</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>14_010_6_0027.bmp</td>\n      <td>[1]</td>\n      <td>[[154, 224, 183, 274]]</td>\n    </tr>\n    <tr>\n      <th>921</th>\n      <td>14_051_6_0029.bmp</td>\n      <td>[1]</td>\n      <td>[[265, 189, 282, 227]]</td>\n    </tr>\n    <tr>\n      <th>1161</th>\n      <td>14_070_5_0031.bmp</td>\n      <td>[1]</td>\n      <td>[[111, 188, 135, 216]]</td>\n    </tr>\n    <tr>\n      <th>540</th>\n      <td>14_040_2_0018.bmp</td>\n      <td>[1]</td>\n      <td>[[300, 318, 316, 345]]</td>\n    </tr>\n    <tr>\n      <th>1310</th>\n      <td>14_075_8_0033.bmp</td>\n      <td>[1]</td>\n      <td>[[188, 86, 240, 118]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"data/train_labels.csv\")\n",
    "train_data = train_data[train_data[\"height\"] == 512]\n",
    "train_data.drop([\"height\", 'width'], inplace=True, axis=1)\n",
    "train_data['bbox'] = train_data[['xmin', 'ymin', 'xmax' , 'ymax']].apply(list, axis=1)\n",
    "train_data['class'] = train_data['class'].map({'Stenosis': 1})\n",
    "train_data = train_data.drop(columns=['xmin', 'ymin', 'xmax' , 'ymax']).groupby('filename', as_index=False).agg(list)\n",
    "train_data_300 = train_data.sample(n=30)\n",
    "train_data_300"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "val_data = train_data.loc[train_data.index.difference(train_data_300.index)].sample(n = 5).reset_index(drop=True)\n",
    "train_data = train_data_300.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "              filename class                    bbox\n0    14_010_1_0037.bmp   [1]  [[125, 227, 171, 266]]\n1    14_051_8_0016.bmp   [1]   [[134, 96, 190, 115]]\n2    14_044_3_0042.bmp   [1]  [[222, 290, 238, 302]]\n3   14_021_34_0030.bmp   [1]  [[370, 152, 396, 174]]\n4    14_017_1_0033.bmp   [1]  [[206, 196, 229, 213]]\n5   14_021_32_0022.bmp   [1]  [[398, 200, 427, 230]]\n6    14_050_9_0020.bmp   [1]  [[259, 131, 272, 165]]\n7    14_094_3_0052.bmp   [1]  [[207, 107, 233, 147]]\n8    14_076_4_0026.bmp   [1]  [[198, 137, 261, 165]]\n9    14_040_7_0009.bmp   [1]   [[86, 208, 101, 235]]\n10   14_050_9_0040.bmp   [1]  [[244, 123, 265, 161]]\n11   14_040_1_0021.bmp   [1]  [[262, 182, 271, 198]]\n12   14_034_7_0044.bmp   [1]  [[157, 101, 189, 124]]\n13  14_021_29_0034.bmp   [1]    [[225, 74, 244, 97]]\n14   14_070_5_0054.bmp   [1]   [[99, 164, 124, 188]]\n15   14_094_2_0036.bmp   [1]  [[141, 128, 163, 154]]\n16   14_070_5_0027.bmp   [1]   [[76, 174, 106, 198]]\n17   14_051_8_0027.bmp   [1]   [[155, 87, 204, 107]]\n18   14_051_5_0037.bmp   [1]  [[153, 119, 201, 139]]\n19   14_040_3_0010.bmp   [1]  [[183, 315, 203, 333]]\n20  14_021_35_0016.bmp   [1]  [[362, 101, 382, 136]]\n21   14_067_4_0028.bmp   [1]  [[269, 224, 288, 270]]\n22   14_040_7_0015.bmp   [1]    [[43, 181, 64, 200]]\n23  14_021_38_0032.bmp   [1]  [[155, 308, 210, 334]]\n24   14_034_6_0024.bmp   [1]  [[139, 110, 161, 142]]\n25   14_010_6_0027.bmp   [1]  [[154, 224, 183, 274]]\n26   14_051_6_0029.bmp   [1]  [[265, 189, 282, 227]]\n27   14_070_5_0031.bmp   [1]  [[111, 188, 135, 216]]\n28   14_040_2_0018.bmp   [1]  [[300, 318, 316, 345]]\n29   14_075_8_0033.bmp   [1]   [[188, 86, 240, 118]]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>class</th>\n      <th>bbox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14_010_1_0037.bmp</td>\n      <td>[1]</td>\n      <td>[[125, 227, 171, 266]]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14_051_8_0016.bmp</td>\n      <td>[1]</td>\n      <td>[[134, 96, 190, 115]]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14_044_3_0042.bmp</td>\n      <td>[1]</td>\n      <td>[[222, 290, 238, 302]]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14_021_34_0030.bmp</td>\n      <td>[1]</td>\n      <td>[[370, 152, 396, 174]]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14_017_1_0033.bmp</td>\n      <td>[1]</td>\n      <td>[[206, 196, 229, 213]]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14_021_32_0022.bmp</td>\n      <td>[1]</td>\n      <td>[[398, 200, 427, 230]]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14_050_9_0020.bmp</td>\n      <td>[1]</td>\n      <td>[[259, 131, 272, 165]]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>14_094_3_0052.bmp</td>\n      <td>[1]</td>\n      <td>[[207, 107, 233, 147]]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14_076_4_0026.bmp</td>\n      <td>[1]</td>\n      <td>[[198, 137, 261, 165]]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14_040_7_0009.bmp</td>\n      <td>[1]</td>\n      <td>[[86, 208, 101, 235]]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>14_050_9_0040.bmp</td>\n      <td>[1]</td>\n      <td>[[244, 123, 265, 161]]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>14_040_1_0021.bmp</td>\n      <td>[1]</td>\n      <td>[[262, 182, 271, 198]]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14_034_7_0044.bmp</td>\n      <td>[1]</td>\n      <td>[[157, 101, 189, 124]]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14_021_29_0034.bmp</td>\n      <td>[1]</td>\n      <td>[[225, 74, 244, 97]]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14_070_5_0054.bmp</td>\n      <td>[1]</td>\n      <td>[[99, 164, 124, 188]]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14_094_2_0036.bmp</td>\n      <td>[1]</td>\n      <td>[[141, 128, 163, 154]]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>14_070_5_0027.bmp</td>\n      <td>[1]</td>\n      <td>[[76, 174, 106, 198]]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>14_051_8_0027.bmp</td>\n      <td>[1]</td>\n      <td>[[155, 87, 204, 107]]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>14_051_5_0037.bmp</td>\n      <td>[1]</td>\n      <td>[[153, 119, 201, 139]]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>14_040_3_0010.bmp</td>\n      <td>[1]</td>\n      <td>[[183, 315, 203, 333]]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>14_021_35_0016.bmp</td>\n      <td>[1]</td>\n      <td>[[362, 101, 382, 136]]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>14_067_4_0028.bmp</td>\n      <td>[1]</td>\n      <td>[[269, 224, 288, 270]]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>14_040_7_0015.bmp</td>\n      <td>[1]</td>\n      <td>[[43, 181, 64, 200]]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>14_021_38_0032.bmp</td>\n      <td>[1]</td>\n      <td>[[155, 308, 210, 334]]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>14_034_6_0024.bmp</td>\n      <td>[1]</td>\n      <td>[[139, 110, 161, 142]]</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>14_010_6_0027.bmp</td>\n      <td>[1]</td>\n      <td>[[154, 224, 183, 274]]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>14_051_6_0029.bmp</td>\n      <td>[1]</td>\n      <td>[[265, 189, 282, 227]]</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>14_070_5_0031.bmp</td>\n      <td>[1]</td>\n      <td>[[111, 188, 135, 216]]</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>14_040_2_0018.bmp</td>\n      <td>[1]</td>\n      <td>[[300, 318, 316, 345]]</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>14_075_8_0033.bmp</td>\n      <td>[1]</td>\n      <td>[[188, 86, 240, 118]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "            filename class                    bbox\n0  14_017_1_0028.bmp   [1]  [[220, 192, 246, 212]]\n1  14_055_6_0019.bmp   [1]   [[87, 153, 124, 176]]\n2  14_067_4_0014.bmp   [1]  [[268, 220, 292, 278]]\n3  14_002_8_0011.bmp   [1]  [[260, 172, 287, 193]]\n4  14_010_6_0034.bmp   [1]   [[94, 250, 134, 287]]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>class</th>\n      <th>bbox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14_017_1_0028.bmp</td>\n      <td>[1]</td>\n      <td>[[220, 192, 246, 212]]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14_055_6_0019.bmp</td>\n      <td>[1]</td>\n      <td>[[87, 153, 124, 176]]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14_067_4_0014.bmp</td>\n      <td>[1]</td>\n      <td>[[268, 220, 292, 278]]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14_002_8_0011.bmp</td>\n      <td>[1]</td>\n      <td>[[260, 172, 287, 193]]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14_010_6_0034.bmp</td>\n      <td>[1]</td>\n      <td>[[94, 250, 134, 287]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, img_path):\n",
    "\n",
    "        self.df = dataframe\n",
    "        self.img_path = img_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.df.loc[index,'filename']\n",
    "        boxes = torch.Tensor(self.df.loc[index, 'bbox']).to(torch.float)\n",
    "        labels = torch.Tensor(self.df.loc[index, 'class']).to(torch.int64)\n",
    "        area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros(labels.shape[0], dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "\n",
    "        img = cv2.imread(os.path.join(self.img_path, img_name))/255.\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1).to(torch.float)\n",
    "        return img, target\n",
    "\n",
    "def create_model(num_classes, pretrained=False):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrained)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\SFU\\Coronarography\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Projects\\SFU\\Coronarography\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ((tensor([[[0.2784, 0.2980, 0.3176,  ..., 0.4353, 0.3961, 0.3647],\n",
      "         [0.2863, 0.2980, 0.3176,  ..., 0.4549, 0.4235, 0.3725],\n",
      "         [0.2941, 0.3059, 0.3176,  ..., 0.4706, 0.4157, 0.3647],\n",
      "         ...,\n",
      "         [0.0588, 0.0706, 0.0627,  ..., 0.0196, 0.0196, 0.0000],\n",
      "         [0.0627, 0.0706, 0.0588,  ..., 0.0118, 0.0118, 0.0039],\n",
      "         [0.0588, 0.0588, 0.0510,  ..., 0.0039, 0.0039, 0.0118]],\n",
      "\n",
      "        [[0.2784, 0.2980, 0.3176,  ..., 0.4353, 0.3961, 0.3647],\n",
      "         [0.2863, 0.2980, 0.3176,  ..., 0.4549, 0.4235, 0.3725],\n",
      "         [0.2941, 0.3059, 0.3176,  ..., 0.4706, 0.4157, 0.3647],\n",
      "         ...,\n",
      "         [0.0588, 0.0706, 0.0627,  ..., 0.0196, 0.0196, 0.0000],\n",
      "         [0.0627, 0.0706, 0.0588,  ..., 0.0118, 0.0118, 0.0039],\n",
      "         [0.0588, 0.0588, 0.0510,  ..., 0.0039, 0.0039, 0.0118]],\n",
      "\n",
      "        [[0.2784, 0.2980, 0.3176,  ..., 0.4353, 0.3961, 0.3647],\n",
      "         [0.2863, 0.2980, 0.3176,  ..., 0.4549, 0.4235, 0.3725],\n",
      "         [0.2941, 0.3059, 0.3176,  ..., 0.4706, 0.4157, 0.3647],\n",
      "         ...,\n",
      "         [0.0588, 0.0706, 0.0627,  ..., 0.0196, 0.0196, 0.0000],\n",
      "         [0.0627, 0.0706, 0.0588,  ..., 0.0118, 0.0118, 0.0039],\n",
      "         [0.0588, 0.0588, 0.0510,  ..., 0.0039, 0.0039, 0.0118]]]), tensor([[[0.0118, 0.0275, 0.0353,  ..., 0.0431, 0.0431, 0.0118],\n",
      "         [0.0118, 0.0196, 0.0275,  ..., 0.0510, 0.0510, 0.0196],\n",
      "         [0.0118, 0.0275, 0.0353,  ..., 0.0510, 0.0275, 0.0353],\n",
      "         ...,\n",
      "         [0.0118, 0.0196, 0.0196,  ..., 0.0118, 0.0118, 0.0196],\n",
      "         [0.0039, 0.0000, 0.0039,  ..., 0.0118, 0.0039, 0.0039],\n",
      "         [0.0118, 0.0118, 0.0000,  ..., 0.0118, 0.0039, 0.0000]],\n",
      "\n",
      "        [[0.0118, 0.0275, 0.0353,  ..., 0.0431, 0.0431, 0.0118],\n",
      "         [0.0118, 0.0196, 0.0275,  ..., 0.0510, 0.0510, 0.0196],\n",
      "         [0.0118, 0.0275, 0.0353,  ..., 0.0510, 0.0275, 0.0353],\n",
      "         ...,\n",
      "         [0.0118, 0.0196, 0.0196,  ..., 0.0118, 0.0118, 0.0196],\n",
      "         [0.0039, 0.0000, 0.0039,  ..., 0.0118, 0.0039, 0.0039],\n",
      "         [0.0118, 0.0118, 0.0000,  ..., 0.0118, 0.0039, 0.0000]],\n",
      "\n",
      "        [[0.0118, 0.0275, 0.0353,  ..., 0.0431, 0.0431, 0.0118],\n",
      "         [0.0118, 0.0196, 0.0275,  ..., 0.0510, 0.0510, 0.0196],\n",
      "         [0.0118, 0.0275, 0.0353,  ..., 0.0510, 0.0275, 0.0353],\n",
      "         ...,\n",
      "         [0.0118, 0.0196, 0.0196,  ..., 0.0118, 0.0118, 0.0196],\n",
      "         [0.0039, 0.0000, 0.0039,  ..., 0.0118, 0.0039, 0.0039],\n",
      "         [0.0118, 0.0118, 0.0000,  ..., 0.0118, 0.0039, 0.0000]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])), ({'boxes': tensor([[154., 224., 183., 274.]]), 'labels': tensor([1])}, {'boxes': tensor([[207., 107., 233., 147.]]), 'labels': tensor([1])}, {'boxes': tensor([[222., 290., 238., 302.]]), 'labels': tensor([1])}))\n",
      "1 ((tensor([[[0.8431, 0.8745, 0.9137,  ..., 0.4196, 0.4039, 0.3843],\n",
      "         [0.8314, 0.8627, 0.9059,  ..., 0.4353, 0.4314, 0.4196],\n",
      "         [0.8275, 0.8588, 0.8902,  ..., 0.4549, 0.4471, 0.4471],\n",
      "         ...,\n",
      "         [0.0588, 0.0667, 0.0667,  ..., 0.0431, 0.0392, 0.0275],\n",
      "         [0.0588, 0.0667, 0.0588,  ..., 0.0235, 0.0235, 0.0235],\n",
      "         [0.0588, 0.0588, 0.0510,  ..., 0.0039, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.8431, 0.8745, 0.9137,  ..., 0.4196, 0.4039, 0.3843],\n",
      "         [0.8314, 0.8627, 0.9059,  ..., 0.4353, 0.4314, 0.4196],\n",
      "         [0.8275, 0.8588, 0.8902,  ..., 0.4549, 0.4471, 0.4471],\n",
      "         ...,\n",
      "         [0.0588, 0.0667, 0.0667,  ..., 0.0431, 0.0392, 0.0275],\n",
      "         [0.0588, 0.0667, 0.0588,  ..., 0.0235, 0.0235, 0.0235],\n",
      "         [0.0588, 0.0588, 0.0510,  ..., 0.0039, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.8431, 0.8745, 0.9137,  ..., 0.4196, 0.4039, 0.3843],\n",
      "         [0.8314, 0.8627, 0.9059,  ..., 0.4353, 0.4314, 0.4196],\n",
      "         [0.8275, 0.8588, 0.8902,  ..., 0.4549, 0.4471, 0.4471],\n",
      "         ...,\n",
      "         [0.0588, 0.0667, 0.0667,  ..., 0.0431, 0.0392, 0.0275],\n",
      "         [0.0588, 0.0667, 0.0588,  ..., 0.0235, 0.0235, 0.0235],\n",
      "         [0.0588, 0.0588, 0.0510,  ..., 0.0039, 0.0000, 0.0000]]]), tensor([[[0.0510, 0.0353, 0.0588,  ..., 0.3843, 0.3333, 0.2941],\n",
      "         [0.0510, 0.0510, 0.0667,  ..., 0.4000, 0.3608, 0.3333],\n",
      "         [0.0353, 0.0588, 0.0588,  ..., 0.4235, 0.3765, 0.3529],\n",
      "         ...,\n",
      "         [0.0000, 0.0039, 0.0196,  ..., 0.0353, 0.0431, 0.0275],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0353, 0.0196, 0.0039],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0275, 0.0196, 0.0039]],\n",
      "\n",
      "        [[0.0510, 0.0353, 0.0588,  ..., 0.3843, 0.3333, 0.2941],\n",
      "         [0.0510, 0.0510, 0.0667,  ..., 0.4000, 0.3608, 0.3333],\n",
      "         [0.0353, 0.0588, 0.0588,  ..., 0.4235, 0.3765, 0.3529],\n",
      "         ...,\n",
      "         [0.0000, 0.0039, 0.0196,  ..., 0.0353, 0.0431, 0.0275],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0353, 0.0196, 0.0039],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0275, 0.0196, 0.0039]],\n",
      "\n",
      "        [[0.0510, 0.0353, 0.0588,  ..., 0.3843, 0.3333, 0.2941],\n",
      "         [0.0510, 0.0510, 0.0667,  ..., 0.4000, 0.3608, 0.3333],\n",
      "         [0.0353, 0.0588, 0.0588,  ..., 0.4235, 0.3765, 0.3529],\n",
      "         ...,\n",
      "         [0.0000, 0.0039, 0.0196,  ..., 0.0353, 0.0431, 0.0275],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0353, 0.0196, 0.0039],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0275, 0.0196, 0.0039]]]), tensor([[[0.3020, 0.3098, 0.3373,  ..., 0.2039, 0.1804, 0.1686],\n",
      "         [0.3098, 0.3137, 0.3333,  ..., 0.2039, 0.1922, 0.1647],\n",
      "         [0.3137, 0.3216, 0.3255,  ..., 0.2039, 0.1922, 0.1686],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0078,  ..., 0.0078, 0.0157, 0.0157],\n",
      "         [0.0078, 0.0039, 0.0078,  ..., 0.0078, 0.0039, 0.0157],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0078, 0.0039, 0.0157]],\n",
      "\n",
      "        [[0.3020, 0.3098, 0.3373,  ..., 0.2039, 0.1804, 0.1686],\n",
      "         [0.3098, 0.3137, 0.3333,  ..., 0.2039, 0.1922, 0.1647],\n",
      "         [0.3137, 0.3216, 0.3255,  ..., 0.2039, 0.1922, 0.1686],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0078,  ..., 0.0078, 0.0157, 0.0157],\n",
      "         [0.0078, 0.0039, 0.0078,  ..., 0.0078, 0.0039, 0.0157],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0078, 0.0039, 0.0157]],\n",
      "\n",
      "        [[0.3020, 0.3098, 0.3373,  ..., 0.2039, 0.1804, 0.1686],\n",
      "         [0.3098, 0.3137, 0.3333,  ..., 0.2039, 0.1922, 0.1647],\n",
      "         [0.3137, 0.3216, 0.3255,  ..., 0.2039, 0.1922, 0.1686],\n",
      "         ...,\n",
      "         [0.0157, 0.0157, 0.0078,  ..., 0.0078, 0.0157, 0.0157],\n",
      "         [0.0078, 0.0039, 0.0078,  ..., 0.0078, 0.0039, 0.0157],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0078, 0.0039, 0.0157]]])), ({'boxes': tensor([[155., 308., 210., 334.]]), 'labels': tensor([1])}, {'boxes': tensor([[188.,  86., 240., 118.]]), 'labels': tensor([1])}, {'boxes': tensor([[300., 318., 316., 345.]]), 'labels': tensor([1])}))\n",
      "2 ((tensor([[[0.7333, 0.7333, 0.7451,  ..., 0.6314, 0.6078, 0.5882],\n",
      "         [0.7333, 0.7451, 0.7569,  ..., 0.6431, 0.6157, 0.6039],\n",
      "         [0.7333, 0.7529, 0.7647,  ..., 0.6706, 0.6431, 0.6275],\n",
      "         ...,\n",
      "         [0.0431, 0.0392, 0.0510,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0392, 0.0314, 0.0314,  ..., 0.0157, 0.0078, 0.0000],\n",
      "         [0.0392, 0.0314, 0.0196,  ..., 0.0039, 0.0039, 0.0000]],\n",
      "\n",
      "        [[0.7333, 0.7333, 0.7451,  ..., 0.6314, 0.6078, 0.5882],\n",
      "         [0.7333, 0.7451, 0.7569,  ..., 0.6431, 0.6157, 0.6039],\n",
      "         [0.7333, 0.7529, 0.7647,  ..., 0.6706, 0.6431, 0.6275],\n",
      "         ...,\n",
      "         [0.0431, 0.0392, 0.0510,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0392, 0.0314, 0.0314,  ..., 0.0157, 0.0078, 0.0000],\n",
      "         [0.0392, 0.0314, 0.0196,  ..., 0.0039, 0.0039, 0.0000]],\n",
      "\n",
      "        [[0.7333, 0.7333, 0.7451,  ..., 0.6314, 0.6078, 0.5882],\n",
      "         [0.7333, 0.7451, 0.7569,  ..., 0.6431, 0.6157, 0.6039],\n",
      "         [0.7333, 0.7529, 0.7647,  ..., 0.6706, 0.6431, 0.6275],\n",
      "         ...,\n",
      "         [0.0431, 0.0392, 0.0510,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0392, 0.0314, 0.0314,  ..., 0.0157, 0.0078, 0.0000],\n",
      "         [0.0392, 0.0314, 0.0196,  ..., 0.0039, 0.0039, 0.0000]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), tensor([[[0.2549, 0.2784, 0.2902,  ..., 0.1569, 0.1451, 0.1373],\n",
      "         [0.2627, 0.2745, 0.2941,  ..., 0.1725, 0.1451, 0.1373],\n",
      "         [0.2667, 0.2784, 0.2902,  ..., 0.1804, 0.1569, 0.1451],\n",
      "         ...,\n",
      "         [0.0706, 0.0627, 0.0706,  ..., 0.0196, 0.0157, 0.0078],\n",
      "         [0.0588, 0.0549, 0.0588,  ..., 0.0078, 0.0000, 0.0000],\n",
      "         [0.0549, 0.0549, 0.0549,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2549, 0.2784, 0.2902,  ..., 0.1569, 0.1451, 0.1373],\n",
      "         [0.2627, 0.2745, 0.2941,  ..., 0.1725, 0.1451, 0.1373],\n",
      "         [0.2667, 0.2784, 0.2902,  ..., 0.1804, 0.1569, 0.1451],\n",
      "         ...,\n",
      "         [0.0706, 0.0627, 0.0706,  ..., 0.0196, 0.0157, 0.0078],\n",
      "         [0.0588, 0.0549, 0.0588,  ..., 0.0078, 0.0000, 0.0000],\n",
      "         [0.0549, 0.0549, 0.0549,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2549, 0.2784, 0.2902,  ..., 0.1569, 0.1451, 0.1373],\n",
      "         [0.2627, 0.2745, 0.2941,  ..., 0.1725, 0.1451, 0.1373],\n",
      "         [0.2667, 0.2784, 0.2902,  ..., 0.1804, 0.1569, 0.1451],\n",
      "         ...,\n",
      "         [0.0706, 0.0627, 0.0706,  ..., 0.0196, 0.0157, 0.0078],\n",
      "         [0.0588, 0.0549, 0.0588,  ..., 0.0078, 0.0000, 0.0000],\n",
      "         [0.0549, 0.0549, 0.0549,  ..., 0.0000, 0.0000, 0.0000]]])), ({'boxes': tensor([[ 86., 208., 101., 235.]]), 'labels': tensor([1])}, {'boxes': tensor([[262., 182., 271., 198.]]), 'labels': tensor([1])}, {'boxes': tensor([[139., 110., 161., 142.]]), 'labels': tensor([1])}))\n",
      "3 ((tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), tensor([[[0.3294, 0.3373, 0.3294,  ..., 0.4549, 0.4000, 0.3529],\n",
      "         [0.3216, 0.3412, 0.3373,  ..., 0.4745, 0.4118, 0.3686],\n",
      "         [0.3216, 0.3294, 0.3294,  ..., 0.4745, 0.4314, 0.3882],\n",
      "         ...,\n",
      "         [0.0314, 0.0353, 0.0235,  ..., 0.0353, 0.0157, 0.0235],\n",
      "         [0.0157, 0.0235, 0.0235,  ..., 0.0314, 0.0157, 0.0157],\n",
      "         [0.0039, 0.0039, 0.0157,  ..., 0.0235, 0.0118, 0.0000]],\n",
      "\n",
      "        [[0.3294, 0.3373, 0.3294,  ..., 0.4549, 0.4000, 0.3529],\n",
      "         [0.3216, 0.3412, 0.3373,  ..., 0.4745, 0.4118, 0.3686],\n",
      "         [0.3216, 0.3294, 0.3294,  ..., 0.4745, 0.4314, 0.3882],\n",
      "         ...,\n",
      "         [0.0314, 0.0353, 0.0235,  ..., 0.0353, 0.0157, 0.0235],\n",
      "         [0.0157, 0.0235, 0.0235,  ..., 0.0314, 0.0157, 0.0157],\n",
      "         [0.0039, 0.0039, 0.0157,  ..., 0.0235, 0.0118, 0.0000]],\n",
      "\n",
      "        [[0.3294, 0.3373, 0.3294,  ..., 0.4549, 0.4000, 0.3529],\n",
      "         [0.3216, 0.3412, 0.3373,  ..., 0.4745, 0.4118, 0.3686],\n",
      "         [0.3216, 0.3294, 0.3294,  ..., 0.4745, 0.4314, 0.3882],\n",
      "         ...,\n",
      "         [0.0314, 0.0353, 0.0235,  ..., 0.0353, 0.0157, 0.0235],\n",
      "         [0.0157, 0.0235, 0.0235,  ..., 0.0314, 0.0157, 0.0157],\n",
      "         [0.0039, 0.0039, 0.0157,  ..., 0.0235, 0.0118, 0.0000]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])), ({'boxes': tensor([[244., 123., 265., 161.]]), 'labels': tensor([1])}, {'boxes': tensor([[134.,  96., 190., 115.]]), 'labels': tensor([1])}, {'boxes': tensor([[ 99., 164., 124., 188.]]), 'labels': tensor([1])}))\n",
      "4 ((tensor([[[0.6118, 0.6471, 0.6706,  ..., 0.6510, 0.6392, 0.6000],\n",
      "         [0.6000, 0.6392, 0.6706,  ..., 0.6588, 0.6392, 0.6078],\n",
      "         [0.6000, 0.6392, 0.6667,  ..., 0.6588, 0.6510, 0.6314],\n",
      "         ...,\n",
      "         [0.0157, 0.0118, 0.0039,  ..., 0.0667, 0.0667, 0.0549],\n",
      "         [0.0235, 0.0235, 0.0039,  ..., 0.0667, 0.0549, 0.0510],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0549, 0.0510, 0.0431]],\n",
      "\n",
      "        [[0.6118, 0.6471, 0.6706,  ..., 0.6510, 0.6392, 0.6000],\n",
      "         [0.6000, 0.6392, 0.6706,  ..., 0.6588, 0.6392, 0.6078],\n",
      "         [0.6000, 0.6392, 0.6667,  ..., 0.6588, 0.6510, 0.6314],\n",
      "         ...,\n",
      "         [0.0157, 0.0118, 0.0039,  ..., 0.0667, 0.0667, 0.0549],\n",
      "         [0.0235, 0.0235, 0.0039,  ..., 0.0667, 0.0549, 0.0510],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0549, 0.0510, 0.0431]],\n",
      "\n",
      "        [[0.6118, 0.6471, 0.6706,  ..., 0.6510, 0.6392, 0.6000],\n",
      "         [0.6000, 0.6392, 0.6706,  ..., 0.6588, 0.6392, 0.6078],\n",
      "         [0.6000, 0.6392, 0.6667,  ..., 0.6588, 0.6510, 0.6314],\n",
      "         ...,\n",
      "         [0.0157, 0.0118, 0.0039,  ..., 0.0667, 0.0667, 0.0549],\n",
      "         [0.0235, 0.0235, 0.0039,  ..., 0.0667, 0.0549, 0.0510],\n",
      "         [0.0039, 0.0039, 0.0000,  ..., 0.0549, 0.0510, 0.0431]]]), tensor([[[0.1333, 0.1098, 0.1216,  ..., 0.2471, 0.2510, 0.2627],\n",
      "         [0.1451, 0.1451, 0.1412,  ..., 0.2471, 0.2588, 0.2510],\n",
      "         [0.1765, 0.1804, 0.1804,  ..., 0.2392, 0.2392, 0.2471],\n",
      "         ...,\n",
      "         [0.1216, 0.1098, 0.1098,  ..., 0.1529, 0.1412, 0.1412],\n",
      "         [0.1098, 0.1176, 0.1059,  ..., 0.1176, 0.1216, 0.1333],\n",
      "         [0.1098, 0.1294, 0.1176,  ..., 0.1098, 0.1098, 0.1412]],\n",
      "\n",
      "        [[0.1333, 0.1098, 0.1216,  ..., 0.2471, 0.2510, 0.2627],\n",
      "         [0.1451, 0.1451, 0.1412,  ..., 0.2471, 0.2588, 0.2510],\n",
      "         [0.1765, 0.1804, 0.1804,  ..., 0.2392, 0.2392, 0.2471],\n",
      "         ...,\n",
      "         [0.1216, 0.1098, 0.1098,  ..., 0.1529, 0.1412, 0.1412],\n",
      "         [0.1098, 0.1176, 0.1059,  ..., 0.1176, 0.1216, 0.1333],\n",
      "         [0.1098, 0.1294, 0.1176,  ..., 0.1098, 0.1098, 0.1412]],\n",
      "\n",
      "        [[0.1333, 0.1098, 0.1216,  ..., 0.2471, 0.2510, 0.2627],\n",
      "         [0.1451, 0.1451, 0.1412,  ..., 0.2471, 0.2588, 0.2510],\n",
      "         [0.1765, 0.1804, 0.1804,  ..., 0.2392, 0.2392, 0.2471],\n",
      "         ...,\n",
      "         [0.1216, 0.1098, 0.1098,  ..., 0.1529, 0.1412, 0.1412],\n",
      "         [0.1098, 0.1176, 0.1059,  ..., 0.1176, 0.1216, 0.1333],\n",
      "         [0.1098, 0.1294, 0.1176,  ..., 0.1098, 0.1098, 0.1412]]]), tensor([[[0.2431, 0.2784, 0.3333,  ..., 0.4235, 0.4000, 0.3686],\n",
      "         [0.2588, 0.2902, 0.3333,  ..., 0.4471, 0.4235, 0.3882],\n",
      "         [0.2784, 0.2941, 0.3412,  ..., 0.4510, 0.4471, 0.4235],\n",
      "         ...,\n",
      "         [0.0157, 0.0078, 0.0275,  ..., 0.0275, 0.0196, 0.0275],\n",
      "         [0.0000, 0.0078, 0.0157,  ..., 0.0275, 0.0196, 0.0275],\n",
      "         [0.0000, 0.0078, 0.0196,  ..., 0.0275, 0.0196, 0.0196]],\n",
      "\n",
      "        [[0.2431, 0.2784, 0.3333,  ..., 0.4235, 0.4000, 0.3686],\n",
      "         [0.2588, 0.2902, 0.3333,  ..., 0.4471, 0.4235, 0.3882],\n",
      "         [0.2784, 0.2941, 0.3412,  ..., 0.4510, 0.4471, 0.4235],\n",
      "         ...,\n",
      "         [0.0157, 0.0078, 0.0275,  ..., 0.0275, 0.0196, 0.0275],\n",
      "         [0.0000, 0.0078, 0.0157,  ..., 0.0275, 0.0196, 0.0275],\n",
      "         [0.0000, 0.0078, 0.0196,  ..., 0.0275, 0.0196, 0.0196]],\n",
      "\n",
      "        [[0.2431, 0.2784, 0.3333,  ..., 0.4235, 0.4000, 0.3686],\n",
      "         [0.2588, 0.2902, 0.3333,  ..., 0.4471, 0.4235, 0.3882],\n",
      "         [0.2784, 0.2941, 0.3412,  ..., 0.4510, 0.4471, 0.4235],\n",
      "         ...,\n",
      "         [0.0157, 0.0078, 0.0275,  ..., 0.0275, 0.0196, 0.0275],\n",
      "         [0.0000, 0.0078, 0.0157,  ..., 0.0275, 0.0196, 0.0275],\n",
      "         [0.0000, 0.0078, 0.0196,  ..., 0.0275, 0.0196, 0.0196]]])), ({'boxes': tensor([[370., 152., 396., 174.]]), 'labels': tensor([1])}, {'boxes': tensor([[198., 137., 261., 165.]]), 'labels': tensor([1])}, {'boxes': tensor([[265., 189., 282., 227.]]), 'labels': tensor([1])}))\n",
      "5 ((tensor([[[0.2706, 0.3176, 0.3529,  ..., 0.2275, 0.2078, 0.2275],\n",
      "         [0.2863, 0.3216, 0.3608,  ..., 0.2275, 0.2275, 0.2196],\n",
      "         [0.3294, 0.3686, 0.3608,  ..., 0.2275, 0.2353, 0.2392],\n",
      "         ...,\n",
      "         [0.0431, 0.0353, 0.0431,  ..., 0.1059, 0.1176, 0.0980],\n",
      "         [0.0471, 0.0235, 0.0314,  ..., 0.0863, 0.0941, 0.0941],\n",
      "         [0.0000, 0.0157, 0.0157,  ..., 0.0745, 0.0941, 0.0980]],\n",
      "\n",
      "        [[0.2706, 0.3176, 0.3529,  ..., 0.2275, 0.2078, 0.2275],\n",
      "         [0.2863, 0.3216, 0.3608,  ..., 0.2275, 0.2275, 0.2196],\n",
      "         [0.3294, 0.3686, 0.3608,  ..., 0.2275, 0.2353, 0.2392],\n",
      "         ...,\n",
      "         [0.0431, 0.0353, 0.0431,  ..., 0.1059, 0.1176, 0.0980],\n",
      "         [0.0471, 0.0235, 0.0314,  ..., 0.0863, 0.0941, 0.0941],\n",
      "         [0.0000, 0.0157, 0.0157,  ..., 0.0745, 0.0941, 0.0980]],\n",
      "\n",
      "        [[0.2706, 0.3176, 0.3529,  ..., 0.2275, 0.2078, 0.2275],\n",
      "         [0.2863, 0.3216, 0.3608,  ..., 0.2275, 0.2275, 0.2196],\n",
      "         [0.3294, 0.3686, 0.3608,  ..., 0.2275, 0.2353, 0.2392],\n",
      "         ...,\n",
      "         [0.0431, 0.0353, 0.0431,  ..., 0.1059, 0.1176, 0.0980],\n",
      "         [0.0471, 0.0235, 0.0314,  ..., 0.0863, 0.0941, 0.0941],\n",
      "         [0.0000, 0.0157, 0.0157,  ..., 0.0745, 0.0941, 0.0980]]]), tensor([[[0.3490, 0.3490, 0.3529,  ..., 0.4824, 0.4392, 0.4000],\n",
      "         [0.3529, 0.3608, 0.3686,  ..., 0.4941, 0.4431, 0.4118],\n",
      "         [0.3490, 0.3529, 0.3608,  ..., 0.4824, 0.4431, 0.4000],\n",
      "         ...,\n",
      "         [0.0353, 0.0353, 0.0353,  ..., 0.0471, 0.0471, 0.0314],\n",
      "         [0.0157, 0.0235, 0.0314,  ..., 0.0431, 0.0431, 0.0314],\n",
      "         [0.0000, 0.0000, 0.0118,  ..., 0.0431, 0.0353, 0.0314]],\n",
      "\n",
      "        [[0.3490, 0.3490, 0.3529,  ..., 0.4824, 0.4392, 0.4000],\n",
      "         [0.3529, 0.3608, 0.3686,  ..., 0.4941, 0.4431, 0.4118],\n",
      "         [0.3490, 0.3529, 0.3608,  ..., 0.4824, 0.4431, 0.4000],\n",
      "         ...,\n",
      "         [0.0353, 0.0353, 0.0353,  ..., 0.0471, 0.0471, 0.0314],\n",
      "         [0.0157, 0.0235, 0.0314,  ..., 0.0431, 0.0431, 0.0314],\n",
      "         [0.0000, 0.0000, 0.0118,  ..., 0.0431, 0.0353, 0.0314]],\n",
      "\n",
      "        [[0.3490, 0.3490, 0.3529,  ..., 0.4824, 0.4392, 0.4000],\n",
      "         [0.3529, 0.3608, 0.3686,  ..., 0.4941, 0.4431, 0.4118],\n",
      "         [0.3490, 0.3529, 0.3608,  ..., 0.4824, 0.4431, 0.4000],\n",
      "         ...,\n",
      "         [0.0353, 0.0353, 0.0353,  ..., 0.0471, 0.0471, 0.0314],\n",
      "         [0.0157, 0.0235, 0.0314,  ..., 0.0431, 0.0431, 0.0314],\n",
      "         [0.0000, 0.0000, 0.0118,  ..., 0.0431, 0.0353, 0.0314]]]), tensor([[[0.1098, 0.1255, 0.1294,  ..., 0.2157, 0.1882, 0.1725],\n",
      "         [0.1176, 0.1137, 0.1176,  ..., 0.2196, 0.1882, 0.1725],\n",
      "         [0.1255, 0.1137, 0.1333,  ..., 0.2235, 0.2000, 0.1765],\n",
      "         ...,\n",
      "         [0.0039, 0.0039, 0.0157,  ..., 0.0980, 0.0824, 0.0784],\n",
      "         [0.0000, 0.0078, 0.0078,  ..., 0.0784, 0.0784, 0.0667],\n",
      "         [0.0000, 0.0039, 0.0039,  ..., 0.0706, 0.0627, 0.0510]],\n",
      "\n",
      "        [[0.1098, 0.1255, 0.1294,  ..., 0.2157, 0.1882, 0.1725],\n",
      "         [0.1176, 0.1137, 0.1176,  ..., 0.2196, 0.1882, 0.1725],\n",
      "         [0.1255, 0.1137, 0.1333,  ..., 0.2235, 0.2000, 0.1765],\n",
      "         ...,\n",
      "         [0.0039, 0.0039, 0.0157,  ..., 0.0980, 0.0824, 0.0784],\n",
      "         [0.0000, 0.0078, 0.0078,  ..., 0.0784, 0.0784, 0.0667],\n",
      "         [0.0000, 0.0039, 0.0039,  ..., 0.0706, 0.0627, 0.0510]],\n",
      "\n",
      "        [[0.1098, 0.1255, 0.1294,  ..., 0.2157, 0.1882, 0.1725],\n",
      "         [0.1176, 0.1137, 0.1176,  ..., 0.2196, 0.1882, 0.1725],\n",
      "         [0.1255, 0.1137, 0.1333,  ..., 0.2235, 0.2000, 0.1765],\n",
      "         ...,\n",
      "         [0.0039, 0.0039, 0.0157,  ..., 0.0980, 0.0824, 0.0784],\n",
      "         [0.0000, 0.0078, 0.0078,  ..., 0.0784, 0.0784, 0.0667],\n",
      "         [0.0000, 0.0039, 0.0039,  ..., 0.0706, 0.0627, 0.0510]]])), ({'boxes': tensor([[141., 128., 163., 154.]]), 'labels': tensor([1])}, {'boxes': tensor([[155.,  87., 204., 107.]]), 'labels': tensor([1])}, {'boxes': tensor([[225.,  74., 244.,  97.]]), 'labels': tensor([1])}))\n",
      "6 ((tensor([[[0.4471, 0.4471, 0.4588,  ..., 0.7490, 0.7216, 0.6902],\n",
      "         [0.4392, 0.4471, 0.4588,  ..., 0.7412, 0.7098, 0.6824],\n",
      "         [0.4471, 0.4471, 0.4549,  ..., 0.7412, 0.7176, 0.6824],\n",
      "         ...,\n",
      "         [0.0039, 0.0118, 0.0118,  ..., 0.0549, 0.0667, 0.0549],\n",
      "         [0.0000, 0.0039, 0.0157,  ..., 0.0549, 0.0667, 0.0627],\n",
      "         [0.0000, 0.0000, 0.0118,  ..., 0.0549, 0.0627, 0.0627]],\n",
      "\n",
      "        [[0.4471, 0.4471, 0.4588,  ..., 0.7490, 0.7216, 0.6902],\n",
      "         [0.4392, 0.4471, 0.4588,  ..., 0.7412, 0.7098, 0.6824],\n",
      "         [0.4471, 0.4471, 0.4549,  ..., 0.7412, 0.7176, 0.6824],\n",
      "         ...,\n",
      "         [0.0039, 0.0118, 0.0118,  ..., 0.0549, 0.0667, 0.0549],\n",
      "         [0.0000, 0.0039, 0.0157,  ..., 0.0549, 0.0667, 0.0627],\n",
      "         [0.0000, 0.0000, 0.0118,  ..., 0.0549, 0.0627, 0.0627]],\n",
      "\n",
      "        [[0.4471, 0.4471, 0.4588,  ..., 0.7490, 0.7216, 0.6902],\n",
      "         [0.4392, 0.4471, 0.4588,  ..., 0.7412, 0.7098, 0.6824],\n",
      "         [0.4471, 0.4471, 0.4549,  ..., 0.7412, 0.7176, 0.6824],\n",
      "         ...,\n",
      "         [0.0039, 0.0118, 0.0118,  ..., 0.0549, 0.0667, 0.0549],\n",
      "         [0.0000, 0.0039, 0.0157,  ..., 0.0549, 0.0667, 0.0627],\n",
      "         [0.0000, 0.0000, 0.0118,  ..., 0.0549, 0.0627, 0.0627]]]), tensor([[[0.1725, 0.1843, 0.2196,  ..., 0.2314, 0.2078, 0.1961],\n",
      "         [0.1725, 0.1882, 0.2196,  ..., 0.2392, 0.2078, 0.1961],\n",
      "         [0.1843, 0.1961, 0.2275,  ..., 0.2314, 0.2078, 0.2000],\n",
      "         ...,\n",
      "         [0.0667, 0.0706, 0.0667,  ..., 0.0157, 0.0039, 0.0000],\n",
      "         [0.0235, 0.0235, 0.0275,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         [0.0118, 0.0039, 0.0157,  ..., 0.0039, 0.0157, 0.0118]],\n",
      "\n",
      "        [[0.1725, 0.1843, 0.2196,  ..., 0.2314, 0.2078, 0.1961],\n",
      "         [0.1725, 0.1882, 0.2196,  ..., 0.2392, 0.2078, 0.1961],\n",
      "         [0.1843, 0.1961, 0.2275,  ..., 0.2314, 0.2078, 0.2000],\n",
      "         ...,\n",
      "         [0.0667, 0.0706, 0.0667,  ..., 0.0157, 0.0039, 0.0000],\n",
      "         [0.0235, 0.0235, 0.0275,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         [0.0118, 0.0039, 0.0157,  ..., 0.0039, 0.0157, 0.0118]],\n",
      "\n",
      "        [[0.1725, 0.1843, 0.2196,  ..., 0.2314, 0.2078, 0.1961],\n",
      "         [0.1725, 0.1882, 0.2196,  ..., 0.2392, 0.2078, 0.1961],\n",
      "         [0.1843, 0.1961, 0.2275,  ..., 0.2314, 0.2078, 0.2000],\n",
      "         ...,\n",
      "         [0.0667, 0.0706, 0.0667,  ..., 0.0157, 0.0039, 0.0000],\n",
      "         [0.0235, 0.0235, 0.0275,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         [0.0118, 0.0039, 0.0157,  ..., 0.0039, 0.0157, 0.0118]]]), tensor([[[0.8706, 0.8784, 0.8902,  ..., 0.1804, 0.1373, 0.1176],\n",
      "         [0.8706, 0.8784, 0.8824,  ..., 0.2000, 0.1608, 0.1333],\n",
      "         [0.8706, 0.8824, 0.8784,  ..., 0.2078, 0.1804, 0.1373],\n",
      "         ...,\n",
      "         [0.0235, 0.0235, 0.0235,  ..., 0.0118, 0.0039, 0.0196],\n",
      "         [0.0196, 0.0039, 0.0118,  ..., 0.0039, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039]],\n",
      "\n",
      "        [[0.8706, 0.8784, 0.8902,  ..., 0.1804, 0.1373, 0.1176],\n",
      "         [0.8706, 0.8784, 0.8824,  ..., 0.2000, 0.1608, 0.1333],\n",
      "         [0.8706, 0.8824, 0.8784,  ..., 0.2078, 0.1804, 0.1373],\n",
      "         ...,\n",
      "         [0.0235, 0.0235, 0.0235,  ..., 0.0118, 0.0039, 0.0196],\n",
      "         [0.0196, 0.0039, 0.0118,  ..., 0.0039, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039]],\n",
      "\n",
      "        [[0.8706, 0.8784, 0.8902,  ..., 0.1804, 0.1373, 0.1176],\n",
      "         [0.8706, 0.8784, 0.8824,  ..., 0.2000, 0.1608, 0.1333],\n",
      "         [0.8706, 0.8824, 0.8784,  ..., 0.2078, 0.1804, 0.1373],\n",
      "         ...,\n",
      "         [0.0235, 0.0235, 0.0235,  ..., 0.0118, 0.0039, 0.0196],\n",
      "         [0.0196, 0.0039, 0.0118,  ..., 0.0039, 0.0118, 0.0118],\n",
      "         [0.0118, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039]]])), ({'boxes': tensor([[269., 224., 288., 270.]]), 'labels': tensor([1])}, {'boxes': tensor([[157., 101., 189., 124.]]), 'labels': tensor([1])}, {'boxes': tensor([[398., 200., 427., 230.]]), 'labels': tensor([1])}))\n",
      "7 ((tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), tensor([[[0.0000, 0.0196, 0.0196,  ..., 0.7098, 0.6471, 0.5922],\n",
      "         [0.0000, 0.0118, 0.0118,  ..., 0.7373, 0.6784, 0.6235],\n",
      "         [0.0118, 0.0000, 0.0118,  ..., 0.7608, 0.7137, 0.6627],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0431, 0.0353, 0.0510],\n",
      "         [0.0039, 0.0039, 0.0118,  ..., 0.0510, 0.0431, 0.0588],\n",
      "         [0.0000, 0.0039, 0.0000,  ..., 0.0431, 0.0588, 0.0510]],\n",
      "\n",
      "        [[0.0000, 0.0196, 0.0196,  ..., 0.7098, 0.6471, 0.5922],\n",
      "         [0.0000, 0.0118, 0.0118,  ..., 0.7373, 0.6784, 0.6235],\n",
      "         [0.0118, 0.0000, 0.0118,  ..., 0.7608, 0.7137, 0.6627],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0431, 0.0353, 0.0510],\n",
      "         [0.0039, 0.0039, 0.0118,  ..., 0.0510, 0.0431, 0.0588],\n",
      "         [0.0000, 0.0039, 0.0000,  ..., 0.0431, 0.0588, 0.0510]],\n",
      "\n",
      "        [[0.0000, 0.0196, 0.0196,  ..., 0.7098, 0.6471, 0.5922],\n",
      "         [0.0000, 0.0118, 0.0118,  ..., 0.7373, 0.6784, 0.6235],\n",
      "         [0.0118, 0.0000, 0.0118,  ..., 0.7608, 0.7137, 0.6627],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0118,  ..., 0.0431, 0.0353, 0.0510],\n",
      "         [0.0039, 0.0039, 0.0118,  ..., 0.0510, 0.0431, 0.0588],\n",
      "         [0.0000, 0.0039, 0.0000,  ..., 0.0431, 0.0588, 0.0510]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])), ({'boxes': tensor([[259., 131., 272., 165.]]), 'labels': tensor([1])}, {'boxes': tensor([[206., 196., 229., 213.]]), 'labels': tensor([1])}, {'boxes': tensor([[ 76., 174., 106., 198.]]), 'labels': tensor([1])}))\n",
      "8 ((tensor([[[0.3490, 0.3490, 0.3686,  ..., 0.4392, 0.4196, 0.3608],\n",
      "         [0.3608, 0.3608, 0.3765,  ..., 0.4471, 0.4196, 0.3765],\n",
      "         [0.3569, 0.3686, 0.3765,  ..., 0.4549, 0.4353, 0.4000],\n",
      "         ...,\n",
      "         [0.0824, 0.0824, 0.0902,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0706, 0.0824, 0.0784,  ..., 0.0039, 0.0118, 0.0118],\n",
      "         [0.0627, 0.0706, 0.0706,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3490, 0.3490, 0.3686,  ..., 0.4392, 0.4196, 0.3608],\n",
      "         [0.3608, 0.3608, 0.3765,  ..., 0.4471, 0.4196, 0.3765],\n",
      "         [0.3569, 0.3686, 0.3765,  ..., 0.4549, 0.4353, 0.4000],\n",
      "         ...,\n",
      "         [0.0824, 0.0824, 0.0902,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0706, 0.0824, 0.0784,  ..., 0.0039, 0.0118, 0.0118],\n",
      "         [0.0627, 0.0706, 0.0706,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3490, 0.3490, 0.3686,  ..., 0.4392, 0.4196, 0.3608],\n",
      "         [0.3608, 0.3608, 0.3765,  ..., 0.4471, 0.4196, 0.3765],\n",
      "         [0.3569, 0.3686, 0.3765,  ..., 0.4549, 0.4353, 0.4000],\n",
      "         ...,\n",
      "         [0.0824, 0.0824, 0.0902,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0706, 0.0824, 0.0784,  ..., 0.0039, 0.0118, 0.0118],\n",
      "         [0.0627, 0.0706, 0.0706,  ..., 0.0000, 0.0000, 0.0000]]]), tensor([[[0.2941, 0.3020, 0.2902,  ..., 0.2588, 0.2118, 0.1922],\n",
      "         [0.2902, 0.3020, 0.3020,  ..., 0.2667, 0.2275, 0.2000],\n",
      "         [0.3137, 0.3137, 0.3137,  ..., 0.2784, 0.2353, 0.2000],\n",
      "         ...,\n",
      "         [0.0118, 0.0157, 0.0235,  ..., 0.0157, 0.0235, 0.0275],\n",
      "         [0.0000, 0.0118, 0.0118,  ..., 0.0275, 0.0275, 0.0118],\n",
      "         [0.0039, 0.0118, 0.0118,  ..., 0.0353, 0.0275, 0.0157]],\n",
      "\n",
      "        [[0.2941, 0.3020, 0.2902,  ..., 0.2588, 0.2118, 0.1922],\n",
      "         [0.2902, 0.3020, 0.3020,  ..., 0.2667, 0.2275, 0.2000],\n",
      "         [0.3137, 0.3137, 0.3137,  ..., 0.2784, 0.2353, 0.2000],\n",
      "         ...,\n",
      "         [0.0118, 0.0157, 0.0235,  ..., 0.0157, 0.0235, 0.0275],\n",
      "         [0.0000, 0.0118, 0.0118,  ..., 0.0275, 0.0275, 0.0118],\n",
      "         [0.0039, 0.0118, 0.0118,  ..., 0.0353, 0.0275, 0.0157]],\n",
      "\n",
      "        [[0.2941, 0.3020, 0.2902,  ..., 0.2588, 0.2118, 0.1922],\n",
      "         [0.2902, 0.3020, 0.3020,  ..., 0.2667, 0.2275, 0.2000],\n",
      "         [0.3137, 0.3137, 0.3137,  ..., 0.2784, 0.2353, 0.2000],\n",
      "         ...,\n",
      "         [0.0118, 0.0157, 0.0235,  ..., 0.0157, 0.0235, 0.0275],\n",
      "         [0.0000, 0.0118, 0.0118,  ..., 0.0275, 0.0275, 0.0118],\n",
      "         [0.0039, 0.0118, 0.0118,  ..., 0.0353, 0.0275, 0.0157]]]), tensor([[[0.6667, 0.6902, 0.7216,  ..., 0.5804, 0.5608, 0.5451],\n",
      "         [0.6745, 0.6941, 0.7176,  ..., 0.6000, 0.5725, 0.5608],\n",
      "         [0.6745, 0.7020, 0.7294,  ..., 0.6196, 0.5922, 0.5765],\n",
      "         ...,\n",
      "         [0.0353, 0.0353, 0.0431,  ..., 0.0078, 0.0039, 0.0000],\n",
      "         [0.0314, 0.0314, 0.0353,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0235, 0.0196, 0.0314,  ..., 0.0039, 0.0039, 0.0000]],\n",
      "\n",
      "        [[0.6667, 0.6902, 0.7216,  ..., 0.5804, 0.5608, 0.5451],\n",
      "         [0.6745, 0.6941, 0.7176,  ..., 0.6000, 0.5725, 0.5608],\n",
      "         [0.6745, 0.7020, 0.7294,  ..., 0.6196, 0.5922, 0.5765],\n",
      "         ...,\n",
      "         [0.0353, 0.0353, 0.0431,  ..., 0.0078, 0.0039, 0.0000],\n",
      "         [0.0314, 0.0314, 0.0353,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0235, 0.0196, 0.0314,  ..., 0.0039, 0.0039, 0.0000]],\n",
      "\n",
      "        [[0.6667, 0.6902, 0.7216,  ..., 0.5804, 0.5608, 0.5451],\n",
      "         [0.6745, 0.6941, 0.7176,  ..., 0.6000, 0.5725, 0.5608],\n",
      "         [0.6745, 0.7020, 0.7294,  ..., 0.6196, 0.5922, 0.5765],\n",
      "         ...,\n",
      "         [0.0353, 0.0353, 0.0431,  ..., 0.0078, 0.0039, 0.0000],\n",
      "         [0.0314, 0.0314, 0.0353,  ..., 0.0078, 0.0078, 0.0078],\n",
      "         [0.0235, 0.0196, 0.0314,  ..., 0.0039, 0.0039, 0.0000]]])), ({'boxes': tensor([[125., 227., 171., 266.]]), 'labels': tensor([1])}, {'boxes': tensor([[153., 119., 201., 139.]]), 'labels': tensor([1])}, {'boxes': tensor([[ 43., 181.,  64., 200.]]), 'labels': tensor([1])}))\n",
      "9 ((tensor([[[0.6784, 0.7216, 0.7608,  ..., 0.0627, 0.0627, 0.0471],\n",
      "         [0.6863, 0.7216, 0.7608,  ..., 0.0706, 0.0627, 0.0549],\n",
      "         [0.6941, 0.7216, 0.7569,  ..., 0.0824, 0.0627, 0.0588],\n",
      "         ...,\n",
      "         [0.0157, 0.0196, 0.0353,  ..., 0.0078, 0.0078, 0.0157],\n",
      "         [0.0196, 0.0314, 0.0353,  ..., 0.0078, 0.0039, 0.0078],\n",
      "         [0.0275, 0.0314, 0.0275,  ..., 0.0039, 0.0039, 0.0000]],\n",
      "\n",
      "        [[0.6784, 0.7216, 0.7608,  ..., 0.0627, 0.0627, 0.0471],\n",
      "         [0.6863, 0.7216, 0.7608,  ..., 0.0706, 0.0627, 0.0549],\n",
      "         [0.6941, 0.7216, 0.7569,  ..., 0.0824, 0.0627, 0.0588],\n",
      "         ...,\n",
      "         [0.0157, 0.0196, 0.0353,  ..., 0.0078, 0.0078, 0.0157],\n",
      "         [0.0196, 0.0314, 0.0353,  ..., 0.0078, 0.0039, 0.0078],\n",
      "         [0.0275, 0.0314, 0.0275,  ..., 0.0039, 0.0039, 0.0000]],\n",
      "\n",
      "        [[0.6784, 0.7216, 0.7608,  ..., 0.0627, 0.0627, 0.0471],\n",
      "         [0.6863, 0.7216, 0.7608,  ..., 0.0706, 0.0627, 0.0549],\n",
      "         [0.6941, 0.7216, 0.7569,  ..., 0.0824, 0.0627, 0.0588],\n",
      "         ...,\n",
      "         [0.0157, 0.0196, 0.0353,  ..., 0.0078, 0.0078, 0.0157],\n",
      "         [0.0196, 0.0314, 0.0353,  ..., 0.0078, 0.0039, 0.0078],\n",
      "         [0.0275, 0.0314, 0.0275,  ..., 0.0039, 0.0039, 0.0000]]]), tensor([[[0.3569, 0.3725, 0.3922,  ..., 0.2980, 0.2980, 0.2980],\n",
      "         [0.3569, 0.3725, 0.4000,  ..., 0.2980, 0.2980, 0.2902],\n",
      "         [0.3647, 0.3922, 0.4078,  ..., 0.2745, 0.2824, 0.2902],\n",
      "         ...,\n",
      "         [0.0118, 0.0039, 0.0039,  ..., 0.1020, 0.1020, 0.1176],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0784, 0.0784, 0.0941],\n",
      "         [0.0000, 0.0000, 0.0039,  ..., 0.0784, 0.0784, 0.0863]],\n",
      "\n",
      "        [[0.3569, 0.3725, 0.3922,  ..., 0.2980, 0.2980, 0.2980],\n",
      "         [0.3569, 0.3725, 0.4000,  ..., 0.2980, 0.2980, 0.2902],\n",
      "         [0.3647, 0.3922, 0.4078,  ..., 0.2745, 0.2824, 0.2902],\n",
      "         ...,\n",
      "         [0.0118, 0.0039, 0.0039,  ..., 0.1020, 0.1020, 0.1176],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0784, 0.0784, 0.0941],\n",
      "         [0.0000, 0.0000, 0.0039,  ..., 0.0784, 0.0784, 0.0863]],\n",
      "\n",
      "        [[0.3569, 0.3725, 0.3922,  ..., 0.2980, 0.2980, 0.2980],\n",
      "         [0.3569, 0.3725, 0.4000,  ..., 0.2980, 0.2980, 0.2902],\n",
      "         [0.3647, 0.3922, 0.4078,  ..., 0.2745, 0.2824, 0.2902],\n",
      "         ...,\n",
      "         [0.0118, 0.0039, 0.0039,  ..., 0.1020, 0.1020, 0.1176],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0784, 0.0784, 0.0941],\n",
      "         [0.0000, 0.0000, 0.0039,  ..., 0.0784, 0.0784, 0.0863]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])), ({'boxes': tensor([[362., 101., 382., 136.]]), 'labels': tensor([1])}, {'boxes': tensor([[183., 315., 203., 333.]]), 'labels': tensor([1])}, {'boxes': tensor([[111., 188., 135., 216.]]), 'labels': tensor([1])}))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = create_model(num_classes=2, pretrained=False).to(device)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "train_dataset = MyDataset(train_data, 'data\\dataset')\n",
    "val_dataset = MyDataset(val_data, 'data\\dataset')\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=3,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "for i, data in enumerate(train_data_loader):\n",
    "    print(i, data)\n",
    "val_data_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def train(train_dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        images, targets = data[0], data[1]\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"\\t #{i} loss: {loss}\")\n",
    "    train_loss = running_loss/len(train_dataloader.dataset)\n",
    "    return train_loss\n",
    "\n",
    "def val(val_dataloader):\n",
    "    running_loss = 0\n",
    "    for data in val_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        images, targets = data[0], data[1]\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "            loss_dict = model(images, targets)\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        running_loss += loss.item()\n",
    "    val_loss = running_loss/len(val_dataloader.dataset)\n",
    "    return val_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t #0 loss: 1.3796247243881226\n",
      "\t #1 loss: 0.8234437704086304\n",
      "\t #2 loss: 0.516444981098175\n",
      "\t #3 loss: 0.26148954033851624\n",
      "\t #4 loss: 0.2166663408279419\n",
      "\t #5 loss: 0.14419978857040405\n",
      "\t #6 loss: 0.14688673615455627\n",
      "\t #7 loss: 0.19654449820518494\n",
      "\t #8 loss: 0.29360783100128174\n",
      "\t #9 loss: 0.18531976640224457\n",
      " #0 train_loss: 0.13880759924650193, val_loss: 0.05693596303462982\n",
      " 2.2   0 \n",
      "\t #0 loss: 0.1401604861021042\n",
      "\t #1 loss: 0.13788187503814697\n",
      "\t #2 loss: 0.11276103556156158\n",
      "\t #3 loss: 0.18126419186592102\n",
      "\t #4 loss: 0.2837604284286499\n",
      "\t #5 loss: 0.12567271292209625\n",
      "\t #6 loss: 0.24073576927185059\n",
      "\t #7 loss: 0.4390694200992584\n",
      "\t #8 loss: 0.18020330369472504\n",
      "\t #9 loss: 0.22643238306045532\n",
      " #1 train_loss: 0.06893138686815897, val_loss: 0.07720650434494018\n",
      " 2.2   1 \n",
      "\t #0 loss: 0.19892814755439758\n",
      "\t #1 loss: 0.23878680169582367\n",
      "\t #2 loss: 0.21417838335037231\n",
      "\t #3 loss: 0.1639784574508667\n",
      "\t #4 loss: 0.192961648106575\n",
      "\t #5 loss: 0.18154308199882507\n",
      "\t #6 loss: 0.13775978982448578\n",
      "\t #7 loss: 0.15864574909210205\n",
      "\t #8 loss: 0.1830998808145523\n",
      "\t #9 loss: 0.1176406517624855\n",
      " #2 train_loss: 0.059584086388349534, val_loss: 0.08591009378433227\n",
      " 2.1   2 \n",
      "\t #0 loss: 0.16030509769916534\n",
      "\t #1 loss: 0.25046107172966003\n",
      "\t #2 loss: 0.15035516023635864\n",
      "\t #3 loss: 0.18217888474464417\n",
      "\t #4 loss: 0.21927163004875183\n",
      "\t #5 loss: 0.2579989731311798\n",
      "\t #6 loss: 0.10868159681558609\n",
      "\t #7 loss: 0.17329828441143036\n",
      "\t #8 loss: 0.24380050599575043\n",
      "\t #9 loss: 0.14016443490982056\n",
      " #3 train_loss: 0.06288385465741157, val_loss: 0.07347456365823746\n",
      " 2.1   3 \n",
      "\t #0 loss: 0.19548611342906952\n",
      "\t #1 loss: 0.22673644125461578\n",
      "\t #2 loss: 0.1950819045305252\n",
      "\t #3 loss: 0.20503567159175873\n",
      "\t #4 loss: 0.24259361624717712\n",
      "\t #5 loss: 0.15717722475528717\n",
      "\t #6 loss: 0.21428583562374115\n",
      "\t #7 loss: 0.26991212368011475\n",
      "\t #8 loss: 0.20474672317504883\n",
      "\t #9 loss: 0.23070724308490753\n",
      " #4 train_loss: 0.07139209657907486, val_loss: 0.08886022269725799\n",
      " 2.1   4 \n",
      "\t #0 loss: 0.268378883600235\n",
      "\t #1 loss: 0.20273759961128235\n",
      "\t #2 loss: 0.19751690328121185\n",
      "\t #3 loss: 0.3025375008583069\n",
      "\t #4 loss: 0.195404514670372\n",
      "\t #5 loss: 0.16368339955806732\n",
      "\t #6 loss: 0.24588027596473694\n",
      "\t #7 loss: 0.19855107367038727\n",
      "\t #8 loss: 0.2401200383901596\n",
      "\t #9 loss: 0.1308211088180542\n",
      " #5 train_loss: 0.07152104328076045, val_loss: 0.10162281394004821\n",
      " 2.1   5 \n",
      "\t #0 loss: 0.20038065314292908\n",
      "\t #1 loss: 0.1606793850660324\n",
      "\t #2 loss: 0.22777068614959717\n",
      "\t #3 loss: 0.15116950869560242\n",
      "\t #4 loss: 0.20170703530311584\n",
      "\t #5 loss: 0.16456590592861176\n",
      "\t #6 loss: 0.2539425492286682\n",
      "\t #7 loss: 0.21498221158981323\n",
      "\t #8 loss: 0.29898181557655334\n",
      "\t #9 loss: 0.2554079592227936\n",
      " #6 train_loss: 0.07098625699679056, val_loss: 0.08453001081943512\n",
      " 2.1   6 \n",
      "\t #0 loss: 0.25732582807540894\n",
      "\t #1 loss: 0.13834050297737122\n",
      "\t #2 loss: 0.25559473037719727\n",
      "\t #3 loss: 0.150309756398201\n",
      "\t #4 loss: 0.22977183759212494\n",
      "\t #5 loss: 0.2220381796360016\n",
      "\t #6 loss: 0.2714129686355591\n",
      "\t #7 loss: 0.15136228501796722\n",
      "\t #8 loss: 0.18581506609916687\n",
      "\t #9 loss: 0.25383445620536804\n",
      " #7 train_loss: 0.07052685370047887, val_loss: 0.08412599265575409\n",
      " 2.1   7 \n",
      "\t #0 loss: 0.24377083778381348\n",
      "\t #1 loss: 0.1572808474302292\n",
      "\t #2 loss: 0.1796654313802719\n",
      "\t #3 loss: 0.19715569913387299\n",
      "\t #4 loss: 0.18118292093276978\n",
      "\t #5 loss: 0.1419346183538437\n",
      "\t #6 loss: 0.1673898994922638\n",
      "\t #7 loss: 0.1549789160490036\n",
      "\t #8 loss: 0.19654494524002075\n",
      "\t #9 loss: 0.17764058709144592\n",
      " #8 train_loss: 0.05991815676291783, val_loss: 0.08801761865615845\n",
      " 2.1   8 \n",
      "\t #0 loss: 0.19405120611190796\n",
      "\t #1 loss: 0.14267142117023468\n",
      "\t #2 loss: 0.1277763545513153\n",
      "\t #3 loss: 0.16520553827285767\n",
      "\t #4 loss: 0.1567794382572174\n",
      "\t #5 loss: 0.18770939111709595\n",
      "\t #6 loss: 0.12788860499858856\n",
      "\t #7 loss: 0.16324971616268158\n",
      "\t #8 loss: 0.17195875942707062\n",
      "\t #9 loss: 0.2448045015335083\n",
      " #9 train_loss: 0.05606983105341593, val_loss: 0.10343070924282075\n",
      " 2.1   9 \n",
      "\t #0 loss: 0.245008185505867\n",
      "\t #1 loss: 0.14310207962989807\n",
      "\t #2 loss: 0.1830599159002304\n",
      "\t #3 loss: 0.2055036574602127\n",
      "\t #4 loss: 0.18232272565364838\n",
      "\t #5 loss: 0.13184265792369843\n",
      "\t #6 loss: 0.20386886596679688\n",
      "\t #7 loss: 0.23544687032699585\n",
      "\t #8 loss: 0.16567495465278625\n",
      "\t #9 loss: 0.1763780117034912\n",
      " #10 train_loss: 0.06240693082412084, val_loss: 0.0688230812549591\n",
      " 2.1   10 \n",
      "\t #0 loss: 0.19085745513439178\n",
      "\t #1 loss: 0.19993636012077332\n",
      "\t #2 loss: 0.2023044228553772\n",
      "\t #3 loss: 0.14488662779331207\n",
      "\t #4 loss: 0.19315245747566223\n",
      "\t #5 loss: 0.15099741518497467\n",
      "\t #6 loss: 0.12157893180847168\n",
      "\t #7 loss: 0.1751524806022644\n",
      "\t #8 loss: 0.17343437671661377\n",
      "\t #9 loss: 0.15879780054092407\n",
      " #11 train_loss: 0.05703661094109217, val_loss: 0.06991852521896362\n",
      " 2.1   11 \n",
      "\t #0 loss: 0.1380157321691513\n",
      "\t #1 loss: 0.13292479515075684\n",
      "\t #2 loss: 0.13283275067806244\n",
      "\t #3 loss: 0.16989918053150177\n",
      "\t #4 loss: 0.17050355672836304\n",
      "\t #5 loss: 0.22938650846481323\n",
      "\t #6 loss: 0.20869208872318268\n",
      "\t #7 loss: 0.14964410662651062\n",
      "\t #8 loss: 0.15742157399654388\n",
      "\t #9 loss: 0.10646269470453262\n",
      " #12 train_loss: 0.05319276625911395, val_loss: 0.07363670468330383\n",
      " 2.1   12 \n",
      "\t #0 loss: 0.1763303130865097\n",
      "\t #1 loss: 0.14026939868927002\n",
      "\t #2 loss: 0.15245169401168823\n",
      "\t #3 loss: 0.13693028688430786\n",
      "\t #4 loss: 0.213995099067688\n",
      "\t #5 loss: 0.1535816788673401\n",
      "\t #6 loss: 0.11623338609933853\n",
      "\t #7 loss: 0.21154087781906128\n",
      "\t #8 loss: 0.12236583977937698\n",
      "\t #9 loss: 0.18558120727539062\n",
      " #13 train_loss: 0.05364265938599904, val_loss: 0.10050560534000397\n",
      " 2.1   13 \n",
      "\t #0 loss: 0.24490763247013092\n",
      "\t #1 loss: 0.1622735559940338\n",
      "\t #2 loss: 0.14703023433685303\n",
      "\t #3 loss: 0.13930319249629974\n",
      "\t #4 loss: 0.14870478212833405\n",
      "\t #5 loss: 0.2079976350069046\n",
      "\t #6 loss: 0.1496884673833847\n",
      "\t #7 loss: 0.17547528445720673\n",
      "\t #8 loss: 0.11795260012149811\n",
      "\t #9 loss: 0.11978447437286377\n",
      " #14 train_loss: 0.05377059529225032, val_loss: 0.09062639772891998\n",
      " 2.1   14 \n",
      "\t #0 loss: 0.2260412722826004\n",
      "\t #1 loss: 0.17397047579288483\n",
      "\t #2 loss: 0.13807928562164307\n",
      "\t #3 loss: 0.16018378734588623\n",
      "\t #4 loss: 0.1670924872159958\n",
      "\t #5 loss: 0.19373388588428497\n",
      "\t #6 loss: 0.20193815231323242\n",
      "\t #7 loss: 0.1267925500869751\n",
      "\t #8 loss: 0.10811827331781387\n",
      "\t #9 loss: 0.14609655737876892\n",
      " #15 train_loss: 0.054734890908002855, val_loss: 0.09260808825492858\n",
      " 2.1   15 \n",
      "\t #0 loss: 0.17517121136188507\n",
      "\t #1 loss: 0.12872862815856934\n",
      "\t #2 loss: 0.20660944283008575\n",
      "\t #3 loss: 0.13411033153533936\n",
      "\t #4 loss: 0.19059930741786957\n",
      "\t #5 loss: 0.2088691145181656\n",
      "\t #6 loss: 0.13158383965492249\n",
      "\t #7 loss: 0.22214648127555847\n",
      "\t #8 loss: 0.1198556125164032\n",
      "\t #9 loss: 0.17184723913669586\n",
      " #16 train_loss: 0.05631737361351649, val_loss: 0.09666329622268677\n",
      " 2.1   16 \n",
      "\t #0 loss: 0.16697023808956146\n",
      "\t #1 loss: 0.19440867006778717\n",
      "\t #2 loss: 0.1353788524866104\n",
      "\t #3 loss: 0.1327507644891739\n",
      "\t #4 loss: 0.13061122596263885\n",
      "\t #5 loss: 0.13977186381816864\n",
      "\t #6 loss: 0.14836688339710236\n",
      "\t #7 loss: 0.16495643556118011\n",
      "\t #8 loss: 0.15550526976585388\n",
      "\t #9 loss: 0.1334291249513626\n",
      " #17 train_loss: 0.050071644286314644, val_loss: 0.10255862772464752\n",
      " 2.1   17 \n",
      "\t #0 loss: 0.1476002335548401\n",
      "\t #1 loss: 0.14997772872447968\n",
      "\t #2 loss: 0.15475013852119446\n",
      "\t #3 loss: 0.18438632786273956\n",
      "\t #4 loss: 0.1723949909210205\n",
      "\t #5 loss: 0.18170127272605896\n",
      "\t #6 loss: 0.1250857710838318\n",
      "\t #7 loss: 0.13500487804412842\n",
      "\t #8 loss: 0.10943213850259781\n",
      "\t #9 loss: 0.17540967464447021\n",
      " #18 train_loss: 0.051191438486178714, val_loss: 0.1081113338470459\n",
      " 2.1   18 \n",
      "\t #0 loss: 0.1579316258430481\n",
      "\t #1 loss: 0.1425774097442627\n",
      "\t #2 loss: 0.13826750218868256\n",
      "\t #3 loss: 0.12912511825561523\n",
      "\t #4 loss: 0.1703626662492752\n",
      "\t #5 loss: 0.12610770761966705\n",
      "\t #6 loss: 0.17830485105514526\n",
      "\t #7 loss: 0.191720113158226\n",
      "\t #8 loss: 0.14339466392993927\n",
      "\t #9 loss: 0.13981714844703674\n",
      " #19 train_loss: 0.05058696021636327, val_loss: 0.09192711412906647\n",
      " 2.1   19 \n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "try:\n",
    "    for epoch in range(20):\n",
    "        start = time.time()\n",
    "        train_loss = train(train_data_loader)\n",
    "        val_loss = val(val_data_loader)\n",
    "        scheduler.step()\n",
    "        print(f\" #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")\n",
    "        end = time.time()\n",
    "        print(f\" {round((end - start) / 60, 1)}   {epoch} \")\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "except KeyboardInterrupt:\n",
    "    print(' ')\n",
    "\n",
    "torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x2292a3e98e0>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax  = plt.subplots()\n",
    "ax.plot(train_losses, label='Train')\n",
    "ax.plot(val_losses, label='Val')\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "ax.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
